{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.019001483917236328s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "Finished in 9.695943832397461s\n",
      "\n",
      "{'label': 'tennis racket', 'confidence': 0.5093067, 'topleft': {'x': 161, 'y': 607}, 'bottomright': {'x': 239, 'y': 756}}\n"
     ]
    }
   ],
   "source": [
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "\n",
    "options = {\"model\": \"cfg/yolo.cfg\", \"load\": \"yolo.weights\", \"threshold\": 0.1}\n",
    "\n",
    "tfnet = TFNet(options)\n",
    "'''\n",
    "imgcv = cv2.imread(\"./sample_img/sample_dog.jpg\")\n",
    "results = tfnet.return_predict(imgcv)\n",
    "'''\n",
    "cap=cv2.VideoCapture(\"bandicam 2019-10-26 22-55-07-780.mp4\")\n",
    "\n",
    "imgcv = cv2.imread(\"./capture.png\")\n",
    "results = tfnet.return_predict(imgcv)\n",
    "cap.set(cv2.CAP_PROP_FPS, 60);\n",
    "for (i,result) in enumerate(results):\n",
    "    if(result[\"confidence\"]>=0.4 and result[\"label\"]==\"person\"):\n",
    "        x=result[\"topleft\"][\"x\"]\n",
    "        w=result[\"bottomright\"]['x']-result[\"topleft\"][\"x\"]\n",
    "        y=result[\"topleft\"][\"y\"]\n",
    "        h=result[\"bottomright\"]['y']-result[\"topleft\"][\"y\"]\n",
    "        imgcv=cv2.rectangle(imgcv,(x,y),(x+w,y+h),(0,255,2),4)\n",
    "        label_position=(x+int(w/2),abs (y-1))\n",
    "        cv2.putText(imgcv,result['label'],label_position,cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,255),2)\n",
    "\n",
    "cv2.imshow(\"image\",imgcv)\n",
    "cv2.waitKey(90000)\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageGrab\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = ImageGrab.grab(bbox=(0,0,1000,780)) #bbox specifies specific region (bbox= x,y,width,height *starts top-left)\n",
    "img_np = np.array(img) #this is the array obtained from conversion\n",
    "frame = cv2.cvtColor(img_np, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"test\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Loading ./bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 0.017000436782836914s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.5 usage\n",
      "Finished in 8.136026620864868s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def label_is_(result,kind):\n",
    "    \"\"\"\n",
    "    indicate whether the result contains kind or not\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : dict\n",
    "        predicted dict from yolo\n",
    "    arg2 : string\n",
    "        kind of object that you want\n",
    "   \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "         kind or not\n",
    "\n",
    "    \"\"\"\n",
    "    return result[\"label\"]==kind\n",
    "\n",
    "def draw_pred(imgcv,confidence=0.5,kind=\"person\"):\n",
    "    \"\"\"\n",
    "    take an image and draw predicted contours with labels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : np.array (image)\n",
    "        predicted dict from yolo\n",
    "    arg2: float (default is 0.5) \n",
    "        threshold to output the predicted object as your needed kind\n",
    "    arg3 : string (default is \"person\") \n",
    "        kind of object that you want\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        image with predicted contours and labels\n",
    "    boolean\n",
    "        frame contains kind or not\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    flag=0\n",
    "    results = tfnet.return_predict(imgcv)\n",
    "    for (i,result) in enumerate(results):\n",
    "        if(result[\"confidence\"]>=confidence and label_is_(result,kind)):\n",
    "            flag=1\n",
    "            x=result[\"topleft\"][\"x\"]\n",
    "            w=result[\"bottomright\"]['x']-result[\"topleft\"][\"x\"]\n",
    "            y=result[\"topleft\"][\"y\"]\n",
    "            h=result[\"bottomright\"]['y']-result[\"topleft\"][\"y\"]\n",
    "            imgcv=cv2.rectangle(imgcv,(x,y),(x+w,y+h),(0,255,2),4)\n",
    "            label_position=(x+int(w/2),abs (y-1))\n",
    "            cv2.putText(imgcv,result['label'],label_position,cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,255),2)\n",
    "    return imgcv,flag\n",
    "def init(options):\n",
    "    tfnet = TFNet(options)\n",
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "options = {\"model\": \"./cfg/yolo.cfg\", \"load\": \"./bin/yolo.weights\", \"threshold\": 0.1,\"gpu\":0.5}\n",
    "\n",
    "mon = {'top': 0, 'left': 0, 'width': 800, 'height': 600}\n",
    "\n",
    "init(options)\n",
    "\n",
    "sct = mss()\n",
    "\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(\"top-10-dumb-robbers-video-digest.mp4\")\n",
    "\n",
    "#example code to read from video\n",
    "while True:\n",
    "    \n",
    "    _,imgcv=cap.read()\n",
    "    imgcv,flag=draw_pred(imgcv,0.3)\n",
    "    cv2.imshow(\"image\",imgcv)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyautogui\n",
    "import imutils\n",
    "\n",
    "\n",
    "while True:\n",
    "    image = pyautogui.screenshot()\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    image=image[:1000,:1000]\n",
    "    cv2.imshow(\"test\", image)\n",
    "    k=cv2.waitKey(1) & 0xFF\n",
    "    if(k==27):\n",
    "        break\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "\n",
    "mon = {'top': 0, 'left': 0, 'width': 800, 'height': 600}\n",
    "\n",
    "sct = mss()\n",
    "while True:\n",
    "    \n",
    "    img = np.array(sct.grab(mon))\n",
    "\n",
    "    cv2.imshow('test',img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    img = np.array(sct.grab(mon))\n",
    "\n",
    "    cv2.imshow('test',img)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "       \n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-17e1f7b99dc7>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-17e1f7b99dc7>\"\u001b[1;36m, line \u001b[1;32m56\u001b[0m\n\u001b[1;33m    global tfnet = TFNet(options)\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def label_is_(result,kind):\n",
    "    \"\"\"\n",
    "    indicate whether the result contains kind or not\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : dict\n",
    "        predicted dict from yolo\n",
    "    arg2 : string\n",
    "        kind of object that you want\n",
    "   \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "         kind or not\n",
    "\n",
    "    \"\"\"\n",
    "    return result[\"label\"]==kind\n",
    "\n",
    "def draw_pred(imgcv,kind=\"person\"):\n",
    "    \"\"\"\n",
    "    take an image and draw predicted contours with labels\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arg1 : np.array (image)\n",
    "        predicted dict from yolo\n",
    "    arg2 : string (default is \"person\") \n",
    "        kind of object that you want\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        image with predicted contours and labels\n",
    "    boolean\n",
    "        frame contains kind or not\n",
    "\n",
    "    \"\"\"\n",
    "    global tfnet\n",
    "    flag=0\n",
    "    results = tfnet.return_predict(imgcv)\n",
    "    for (i,result) in enumerate(results):\n",
    "        if(result[\"confidence\"]>=0.4 and label_is_(result,kind)):\n",
    "            flag=1\n",
    "            x=result[\"topleft\"][\"x\"]\n",
    "            w=result[\"bottomright\"]['x']-result[\"topleft\"][\"x\"]\n",
    "            y=result[\"topleft\"][\"y\"]\n",
    "            h=result[\"bottomright\"]['y']-result[\"topleft\"][\"y\"]\n",
    "            imgcv=cv2.rectangle(imgcv,(x,y),(x+w,y+h),(0,255,2),4)\n",
    "            label_position=(x+int(w/2),abs (y-1))\n",
    "            cv2.putText(imgcv,result['label'],label_position,cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,255),2)\n",
    "    return imgcv,flag\n",
    "def init(options):\n",
    "    global tfnet\n",
    "    tfnet = TFNet(options)\n",
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "options = {\"model\": \"./cfg/yolo.cfg\", \"load\": \"./bin/yolo.weights\", \"threshold\": 0.1,\"gpu\":0.5}\n",
    "\n",
    "mon = {'top': 0, 'left': 0, 'width': 800, 'height': 600}\n",
    "\n",
    "init(options)\n",
    "\n",
    "sct = mss()\n",
    "\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(\"top-10-dumb-robbers-video-digest.mp4\")\n",
    "\n",
    "#example code to read from video\n",
    "while True:\n",
    "    \n",
    "    imgcv = np.array(sct.grab(mon))\n",
    "    imgcv = cv2.cvtColor(imgcv, cv2.COLOR_RGB2BGR)\n",
    "    imgcv = cv2.cvtColor(imgcv, cv2.COLOR_BGR2RGB)\n",
    "    imgcv,flag=draw_pred(imgcv)\n",
    "    cv2.imshow(\"image\",imgcv)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
